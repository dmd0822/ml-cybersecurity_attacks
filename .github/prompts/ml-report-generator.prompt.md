---
description: 'This prompt instructs GitHub Copilot to locate the latest analysis notebook in the workspace and generate a polished, fully structured Markdown report summarizing the project’s methodology, results, and reflections. The report is saved under reports/ and follows a strict numbered 1–4 section format with required subsections, narrative, and referenced visualizations.'
agent: 'agent'
---


Scan the workspace for the latest analysis notebook generated by the ML experiment analysis workflow. Use its contents (plots, metrics, tables, and narrative) to create a polished Markdown report. Save the report in a folder named reports/ at the root of the workspace. The report filename must include the current date (e.g., report_2025-12-23.md).

Instructions for GitHub Copilot
You are an assistant that generates a complete, well‑structured Markdown report summarizing the results of a Machine Learning project. Follow these instructions exactly.
1. Locate the Latest Analysis Notebook
- Search the workspace for notebooks matching the naming pattern used by the analysis workflow (e.g., analysis_*.ipynb).
- Identify the most recent notebook based on timestamp in the filename or file modification time.
- Extract relevant content from the notebook:
- Final model metrics
- Loss/accuracy curves
- Confusion matrix
- Per‑class metrics
- Dataset‑specific evaluations
- Any narrative or metadata included in the notebook header

2. Create the Report File
- Create a folder named reports/ at the root of the workspace if it does not already exist.
- Create a new Markdown file named with the current date, e.g.:
report_2025-12-23.md
- All content must be written in clean, readable Markdown.

3. Report Structure Requirements
Your report must begin with a Title Section containing:
- Project Title
- Date
- Dataset Used (optional but helpful)

Formatting rules:
- Use Markdown headings:
	- `#` for the report title
	- `##` for top-level numbered sections (e.g., `## 1: Introduction and Problem Definition`)
	- `###` for subsections (e.g., `### 1.1 Problem description and motivation`)
- Preserve the exact section titles and numbering specified below.

4. Required Sections (Use Titles Exactly as Written)
1: Introduction and Problem Definition
Include the following:
1.1 Problem description and motivation
- Describe the classification problem.
- Explain why it matters.
- You may invent a realistic business or organizational context.
1.2 Project goals
- Business goal: What real‑world outcome the model supports
- Data‑science goal: What the model predicts and under what constraints
1.3 Dataset description
Summarize:
- Number of classes and class distribution
- Input modalities
- Key features
- Challenges (imbalance, noise, mislabeled data, class overlap, etc.)
Include a brief EDA summary (tables or referenced plots).

2: Methodology
Explain the full modeling workflow with enough detail for reproducibility.
2.1 Preprocessing Pipeline
Describe how inputs were prepared. Examples:
- Images: resizing, normalization, augmentation, sampling
- Text: tokenization, vectorization, handling rare words
Include relevant statistics or visualizations.
2.2 Model architecture and justification
Describe:
- Why the chosen model is appropriate
- Key architectural components (CNN blocks, dropout, embeddings, pretrained backbones, etc.)
2.3 Training strategy
Specify:
- Loss function
- Optimizer and learning rate schedule
- Regularization
- Hyperparameters (batch size, epochs, etc.)
- Callbacks (early stopping, checkpoints, LR reduction)
2.4 Performance validation
Describe:
- Training/validation split
- Test set procedure
- Stratification or balancing
- Steps taken to avoid data leakage

3: Results and Evaluation
Present and interpret the performance of the final model.
3.1 Quantitative results
Include:
- Training, validation, and test accuracy
- Training and validation loss curves
- Confusion matrix
- Dataset‑specific metrics (per‑class accuracy, macro‑F1, weighted‑F1, top‑k accuracy, class‑frequency table)
3.2 Interpretation of results
Explain:
- Which classes are easiest/hardest
- Patterns in the confusion matrix
- Evidence of overfitting or underfitting
- Impact of dataset characteristics (e.g., image quality, imbalance)
3.3 Summary of final model performance
Explain:
- Why this model is the “best” solution
- What its performance indicates about task difficulty
- Any surprising behaviors, strengths, or weaknesses

4: Discussion and Reflection
Provide a thoughtful, critical evaluation of the project.
4.1 Limitations and sources of error
Discuss:
- Data issues (noise, imbalance, ambiguity, similarity between classes)
- Model limitations (capacity, representation limits, sensitivity to hyperparameters)
4.2 Potential improvements
Propose at least three specific improvements, such as:
- Stronger augmentation
- Class‑weighted or focal loss
- More expressive architecture
- Better tokenization or embeddings
- Additional data cleaning or balancing
4.3 Reflection on what you learned
Reflect on:
- What mattered most for performance
- Insights about tuning, optimization, or generalization
- What you would do differently next time
- What the dataset and model behavior taught you

5. Output Requirements
The final Markdown report must:
- Be polished, readable, and professionally structured
- Use the exact section titles and numbering specified
- Integrate plots and tables by referencing their filenames or embedding them if appropriate
- Accurately reflect the contents of the latest analysis notebook
- Be saved in the reports/ folder
