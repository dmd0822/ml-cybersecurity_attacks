# `data/02-preprocessed/`

This folder stores **cleaned and standardized datasets** derived from `data/01-raw/`.

Preprocessing typically includes parsing, normalization, deduplication, basic validation, and joining reference data.

## What belongs here

- Clean tables ready for feature engineering
- Standardized schemas and normalized units
- Train/validation/test splits (if you store them as data artifacts)

## Conventions (recommended)

- Keep preprocessing outputs deterministic and reproducible.
- Track schema expectations (columns, types, nullability).
- Avoid leaking target information into preprocessing outputs.

## Example structure

```text
data/02-preprocessed/
  dataset_name/
    v1/
```

## How This Fits

- Upstream: raw inputs in [`data/01-raw/`](../01-raw/)
- Downstream: feature artifacts in [`data/03-features/`](../03-features/)
- Generated by pipeline code in [`src/pipelines/`](../../src/pipelines/)

